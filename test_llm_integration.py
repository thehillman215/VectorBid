#!/usr/bin/env python3
"""
Test script for LLM integration
Run this to verify the LLM preference parser is working
"""

import asyncio
import os
from pathlib import Path

# Add the app directory to the path
import sys
sys.path.append(str(Path(__file__).parent))

async def test_llm_parser():
    """Test the LLM preference parser"""
    
    print("ğŸ§ª Testing LLM Preference Parser")
    print("=" * 50)
    
    # Check if API key is set
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY not set - will test fallback only")
        print("   Set your OpenAI API key to test full LLM functionality")
        print("   export OPENAI_API_KEY='your-key-here'")
    else:
        print(f"âœ… OpenAI API key found: {api_key[:10]}...")
    
    try:
        from app.services.llm_parser import PreferenceParser
        print("âœ… LLM parser imported successfully")
        
        parser = PreferenceParser()
        print("âœ… Parser initialized")
        
        # Test cases
        test_cases = [
            {
                "text": "I want weekends off and prefer morning departures, avoid red-eyes",
                "context": {"base": "SFO", "equipment": ["737", "757"], "seniority_percentile": 0.65}
            },
            {
                "text": "Maximize my credit hours but keep trips under 4 days", 
                "context": {"base": "ORD", "equipment": ["777"], "seniority_percentile": 0.85}
            },
            {
                "text": "Family first - weekends and holidays off, short trips only",
                "persona": "family_first",
                "context": {"base": "EWR", "equipment": ["737"], "seniority_percentile": 0.45}
            }
        ]
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ§ª Test Case {i}: '{test_case['text']}'")
            print("-" * 40)
            
            try:
                result = await parser.parse_preferences(
                    text=test_case["text"],
                    persona=test_case.get("persona"),
                    pilot_context=test_case["context"]
                )
                
                print(f"âœ… Success: {result.parsing_method.value}")
                print(f"ğŸ¯ Confidence: {result.confidence:.2f}")
                print(f"ğŸ§  Model: {result.model_version}")
                print(f"ğŸ’° Tokens: {result.tokens_used}")
                print(f"ğŸ“ Reasoning: {result.reasoning}")
                
                # Show parsed preferences
                prefs = result.preferences
                print(f"ğŸ”’ Hard Constraints: {prefs.hard_constraints}")
                print(f"âš–ï¸  Soft Preferences: {prefs.soft_prefs}")
                
                if result.suggestions:
                    print(f"ğŸ’¡ Suggestions: {result.suggestions}")
                if result.warnings:
                    print(f"âš ï¸  Warnings: {result.warnings}")
                    
            except Exception as e:
                print(f"âŒ Failed: {e}")
        
        print(f"\n{'='*50}")
        print("ğŸ‰ LLM Integration Test Complete!")
        
    except ImportError as e:
        print(f"âŒ Import failed: {e}")
        print("   Make sure dependencies are installed:")
        print("   pip install openai anthropic tiktoken tenacity")
    except Exception as e:
        print(f"âŒ Test failed: {e}")


async def test_api_integration():
    """Test the API integration"""
    print("\nğŸŒ Testing API Integration")
    print("=" * 50)
    
    try:
        import requests
        import json
        
        # Test the parse_preferences endpoint
        url = "http://localhost:8000/api/parse_preferences"
        
        test_payload = {
            "preferences_text": "I want weekends off and prefer morning departures",
            "persona": "family_first",
            "airline": "UAL",
            "pilot_context": {
                "base": "SFO",
                "equipment": ["737"],
                "seniority_percentile": 0.65
            }
        }
        
        print(f"ğŸ“¡ Making request to {url}")
        print(f"ğŸ“¦ Payload: {json.dumps(test_payload, indent=2)}")
        
        response = requests.post(url, json=test_payload, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… API Request Successful!")
            print(f"ğŸ“Š Method: {result.get('method', 'unknown')}")
            print(f"ğŸ¯ Confidence: {result.get('confidence', 0):.2f}")
            print(f"ğŸ“ Reasoning: {result.get('reasoning', 'N/A')}")
        else:
            print(f"âŒ API Request Failed: {response.status_code}")
            print(f"ğŸ“„ Response: {response.text}")
            
    except ImportError:
        print("âš ï¸ requests library not available - skipping API test")
        print("   Install with: pip install requests")
    except Exception as e:
        print(f"âŒ API test failed: {e}")
        print("   Make sure the server is running: uvicorn app.main:app --reload")


if __name__ == "__main__":
    print("VectorBid LLM Integration Test")
    print("=" * 50)
    
    # Run LLM parser test
    asyncio.run(test_llm_parser())
    
    # Run API integration test (optional)
    answer = input("\nğŸ¤” Test API integration? (requires server running) [y/N]: ")
    if answer.lower() in ['y', 'yes']:
        asyncio.run(test_api_integration())
    
    print("\nâœ¨ All tests complete!")